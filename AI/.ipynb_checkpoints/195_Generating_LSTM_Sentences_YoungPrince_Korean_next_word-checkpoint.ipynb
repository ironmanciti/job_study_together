{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZyxyanlZ5aJp"
   },
   "source": [
    "# 195. Keras API 와 LSTM 을 이용한 한글 어린왕자 문장 생성기\n",
    "\n",
    "- next word 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOwsuGQQY9OL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.regularizers as regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "uQ9SxfUSTtmb",
    "outputId": "6d9bbc4e-a25b-4823-b893-6c075fddda03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "n19R9Jpy5aJu",
    "outputId": "534ac98f-3054-4ed1-ec32-f261efe0d646"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'여섯 살 적에 나는 \"체험한 이야기\"라는 제목의, 원시림에 관한 책에서 기막힌 그림 하나를 본 적이 있다. 맹수를 집어삼키고 있는 보아 구렁이 그림이었다. 위의 그림은 그것을 옮겨 그린 것이다. 그 책에는 이렇게 씌어 있었다. \"보아 구렁이는 먹이를 씹지도 않고 통째로 집어삼킨다.그리고는 꼼짝도 하지 못하고 여섯 달 동안 잠을 자면서 그것을 소화시킨다.\" 나는 그래서 밀림 속에서의 모험에 대해 한참 생각해 보고 난 끝에 색연필을 가지고 내 나름대로 내 생애 첫번째 그림을 그려보았다. 나의 그림 제 1호였다. 그것은 이런 그림이었다. 나는 그 걸작품을 어른들에게 보여 주면서내 그림이 무섭지 않느냐고 물었다. 그들은 \"모자가 뭐가 무섭다는 거니?\" 하고 대답했다. 내 그림은 모자를 그린 게 아니었다. 그것은 코끼리를 소화시키고 있는 보아 구렁이었다. 그래서 나는 어른들이 알아볼 수 있도록 보아 구렁이의 속을 그렸다. 어른들은 언제나 설명을 해주어야만 한다. 나의 그림 제 2호는 이러했다. 어른들은 속이 보이거나 보이지 않거나 하는 보아 구렁이의 그림들은 집어치우고 차라리 지리, 역사, 계산, 그리고 문법 쪽에 관심을 가져보는 게 좋을 것이라고 충고해 주었다. 그래서 나는 여섯 살 적에 화가라는 멋진 직업을 포기해 버렸다.내 그림제 1호와 제 2호가 성공을 거두지 못한 데 낙심해 버렸던 것이다. 어른들은언제나 스스로는 아무것도 이해하지 못한다.자꾸자꾸 설명을 해주어야 하니 맥빠지는 노릇이 아닐 수 없다. 그래서 다른 직업을 선택하지 않을 수 없게 된 나는 비행기 조종하는 법을배웠다.세계의 여기저기 거의 안 가본 데 없이 나는 날아다녔다.그러니지리는 정말로 많은 도움을 준 셈이었다.한번 슬쩍 보고도 중국과 애리조나를 나는 구별할 수 있었던 것이다.그것은 밤에 길을 잃었을 때 아주 유용한 일이다. 나는 그리하여 일생 동안 수없이 많은 점잖은 사람들과수많은 접촉을 가져왔다.어른들 틈에서 많이 살아온 것이다.나는 가까이서 그들을 볼 수있었다. 그렇다고 해서 그들에 대한 내'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = open(\"/content/drive/My Drive/data/young_prince.txt\", 'r')\n",
    "\n",
    "texts = r.readlines()\n",
    "lines = []\n",
    "\n",
    "for line in texts:\n",
    "    line = line.strip().lower()\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "\n",
    "text = \" \".join(lines)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SZhigNh5aJx"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "corpus = re.split('[,.]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "zk-Kn9785aJ0",
    "outputId": "8657c998-81e4-4f47-c290-96d79c00047f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['여섯 살 적에 나는 \"체험한 이야기\"라는 제목의',\n",
       " ' 원시림에 관한 책에서 기막힌 그림 하나를 본 적이 있다',\n",
       " ' 맹수를 집어삼키고 있는 보아 구렁이 그림이었다',\n",
       " ' 위의 그림은 그것을 옮겨 그린 것이다',\n",
       " ' 그 책에는 이렇게 씌어 있었다',\n",
       " ' \"보아 구렁이는 먹이를 씹지도 않고 통째로 집어삼킨다',\n",
       " '그리고는 꼼짝도 하지 못하고 여섯 달 동안 잠을 자면서 그것을 소화시킨다',\n",
       " '\" 나는 그래서 밀림 속에서의 모험에 대해 한참 생각해 보고 난 끝에 색연필을 가지고 내 나름대로 내 생애 첫번째 그림을 그려보았다',\n",
       " ' 나의 그림 제 1호였다',\n",
       " ' 그것은 이런 그림이었다']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "B0aXEN_15aJ2",
    "outputId": "8cfcdcb1-c264-47a3-b00f-cb1cfd6fbf06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4594\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rn-AIOff5aJ4"
   },
   "outputs": [],
   "source": [
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "tsplC63C5aJ6",
    "outputId": "cde3e050-b60b-4809-d9c3-aead806a7724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[142, 245],\n",
       " [142, 245, 371],\n",
       " [142, 245, 371, 3],\n",
       " [142, 245, 371, 3, 1322],\n",
       " [142, 245, 371, 3, 1322, 739],\n",
       " [142, 245, 371, 3, 1322, 739, 372],\n",
       " [142, 245, 371, 3, 1322, 739, 372, 1323],\n",
       " [1324, 1325],\n",
       " [1324, 1325, 1326],\n",
       " [1324, 1325, 1326, 1327]]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(input_sequences))\n",
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "-kSzQM4p5aJ8",
    "outputId": "a312f3cb-685c-46b5-84f5-ec65cd442c2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,  142,  245],\n",
       "       [   0,    0,    0, ...,  142,  245,  371],\n",
       "       [   0,    0,    0, ...,  245,  371,    3],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 4591, 1139, 4592],\n",
       "       [   0,    0,    0, ..., 1139, 4592, 4593],\n",
       "       [   0,    0,    0, ..., 4592, 4593,  525]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yU3N25jx5aJ-"
   },
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWPQPgs05aKB"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[-1]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "PlE-4oP55aKF",
    "outputId": "3f44bce9-ea45-44c3-a37a-becb7587002b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   0    0    0 ...    0    0  142]\n",
      " [   0    0    0 ...    0  142  245]\n",
      " [   0    0    0 ...  142  245  371]\n",
      " ...\n",
      " [   0    0    0 ...  128  189 1418]\n",
      " [   0    0    0 ...  189 1418 1419]\n",
      " [   0    0    0 ...    0    0   23]], shape=(256, 51), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[ 245  371    3 1322  739  372 1323 1325 1326 1327  207  740   87  126\n",
      "  143 1329   10  113  373  741  298  144  742  246   13  743   61 1330\n",
      "   20  744 1331 1332  186 1333 1334  745   43  493  142 1335  299  247\n",
      " 1336  144 1337   17 1338 1339 1340  114  374  300  167   14 1341 1342\n",
      "   91   11 1343   11 1344  746  145 1345  207  248 1346  168  741    2\n",
      " 1347  747  748 1348 1349  749 1350   33  750  751 1351  494   21   28\n",
      "  298  375  246   26  376  752 1352   10  113 1353    3  495  496    9\n",
      " 1354  113  497 1355  249  127  498 1356  147  207  248 1357 1358  301\n",
      "  499   81  753   27  113  497 1359 1360 1361  754 1362 1363 1364  757\n",
      "   26  758  759 1365  377    3  142  245  371 1366  500  501  502  250\n",
      " 1367 1368  248 1369 1370 1371  503  251 1372 1373   13 1375  106  504\n",
      "  760  498  761  762 1377 1378 1379    9  252   39  501 1380  169    9\n",
      "  302  115    3 1381 1382 1383 1385  763  253 1386  251  505    3 1387\n",
      "  208   88 1389  148 1390  764 1391 1392 1393    3  765    9  187   13\n",
      "  506  149 1394  116   34 1395  766  254 1396  299 1397   88 1398 1399\n",
      " 1400 1401 1402  768 1403   13 1404  209  210 1405  255 1407  303   11\n",
      "  188 1408   63 1409  304  507  769 1410  770 1411 1412  379 1413   76\n",
      "  207  248 1414   91    2  507 1415 1416   57   29 1417  256  128  189\n",
      " 1418 1419   13 1420], shape=(256,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = text_dataset.map(split_input_target).batch(256, drop_remainder=True)\n",
    "\n",
    "for input, target in dataset.take(1):\n",
    "  print(input)\n",
    "  print()\n",
    "  print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "PRnDnCW-Z7qv",
    "outputId": "dc443120-c6de-4781-d375-48f67bf6a094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         459400    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 64)          34048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2297)              39049     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4594)              10557012  \n",
      "=================================================================\n",
      "Total params: 11,094,693\n",
      "Trainable params: 11,094,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AIg2f1HBxqof",
    "outputId": "adbda13a-6d8f-43f1-ac37-d9a70453471f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 8.4059 - accuracy: 0.0094\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.8173 - accuracy: 0.0113\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.7262 - accuracy: 0.0119\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.5676 - accuracy: 0.0095\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.4795 - accuracy: 0.0097\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.4204 - accuracy: 0.0097\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.3693 - accuracy: 0.0074\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.3287 - accuracy: 0.0075\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.3024 - accuracy: 0.0078\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.2796 - accuracy: 0.0092\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.2550 - accuracy: 0.0098\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.2256 - accuracy: 0.0080\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.1906 - accuracy: 0.0088\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.1530 - accuracy: 0.0100\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.1213 - accuracy: 0.0118\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.0796 - accuracy: 0.0107\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 7.0530 - accuracy: 0.0114\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 7.0210 - accuracy: 0.0139\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.9859 - accuracy: 0.0155\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.9556 - accuracy: 0.0125\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.9313 - accuracy: 0.0149\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.9062 - accuracy: 0.0150\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.8898 - accuracy: 0.0163\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.8659 - accuracy: 0.0155\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.8251 - accuracy: 0.0179\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.7932 - accuracy: 0.0181\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.7731 - accuracy: 0.0200\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.7435 - accuracy: 0.0227\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.7161 - accuracy: 0.0240\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.6987 - accuracy: 0.0226\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.6902 - accuracy: 0.0273\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.6451 - accuracy: 0.0265\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.5950 - accuracy: 0.0282\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.5847 - accuracy: 0.0284\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.5618 - accuracy: 0.0269\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.5437 - accuracy: 0.0278\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.5399 - accuracy: 0.0273\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.5180 - accuracy: 0.0318\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.4708 - accuracy: 0.0348\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.4267 - accuracy: 0.0344\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.3805 - accuracy: 0.0349\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.3162 - accuracy: 0.0371\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.2598 - accuracy: 0.0380\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.2173 - accuracy: 0.0400\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.1855 - accuracy: 0.0387\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.1411 - accuracy: 0.0417\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.1396 - accuracy: 0.0413\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.1141 - accuracy: 0.0423\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.0820 - accuracy: 0.0473\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.0827 - accuracy: 0.0480\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 6.0855 - accuracy: 0.0494\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 6.0201 - accuracy: 0.0489\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.9455 - accuracy: 0.0551\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.8751 - accuracy: 0.0579\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.8274 - accuracy: 0.0612\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.7759 - accuracy: 0.0605\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.7488 - accuracy: 0.0615\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 5.7129 - accuracy: 0.0618\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.6869 - accuracy: 0.0625\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.6535 - accuracy: 0.0643\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.6123 - accuracy: 0.0690\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.5908 - accuracy: 0.0681\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 5.5444 - accuracy: 0.0705\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.5004 - accuracy: 0.0741\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.4827 - accuracy: 0.0760\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.5075 - accuracy: 0.0771\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.4201 - accuracy: 0.0769\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.3699 - accuracy: 0.0792\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.3422 - accuracy: 0.0822\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.3010 - accuracy: 0.0850\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.2373 - accuracy: 0.0858\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 5.1997 - accuracy: 0.0922\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.1554 - accuracy: 0.0923\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.1034 - accuracy: 0.0951\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.0605 - accuracy: 0.0988\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 5.0309 - accuracy: 0.1008\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.9950 - accuracy: 0.1033\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.9567 - accuracy: 0.1051\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.9235 - accuracy: 0.1058\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.8813 - accuracy: 0.1096\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.8571 - accuracy: 0.1105\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.8234 - accuracy: 0.1086\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.7897 - accuracy: 0.1162\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.7528 - accuracy: 0.1207\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.7137 - accuracy: 0.1248\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.6737 - accuracy: 0.1271\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.6415 - accuracy: 0.1268\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.5959 - accuracy: 0.1324\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.5496 - accuracy: 0.1352\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.5145 - accuracy: 0.1408\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.4781 - accuracy: 0.1419\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.4417 - accuracy: 0.1466\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 4.4183 - accuracy: 0.1482\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.3751 - accuracy: 0.1487\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.3602 - accuracy: 0.1557\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.3404 - accuracy: 0.1562\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.3300 - accuracy: 0.1538\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.2967 - accuracy: 0.1592\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.2608 - accuracy: 0.1653\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.2288 - accuracy: 0.1696\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.2093 - accuracy: 0.1702\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.1715 - accuracy: 0.1734\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.1605 - accuracy: 0.1749\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.1487 - accuracy: 0.1794\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.1442 - accuracy: 0.1822\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.1224 - accuracy: 0.1833\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 4.0839 - accuracy: 0.1906\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.0765 - accuracy: 0.1899\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.0213 - accuracy: 0.1947\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.9878 - accuracy: 0.2025\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.9457 - accuracy: 0.2086\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.9157 - accuracy: 0.2148\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.8680 - accuracy: 0.2204\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 3.8299 - accuracy: 0.2245\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.7892 - accuracy: 0.2294\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.7471 - accuracy: 0.2419\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.7348 - accuracy: 0.2440\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.7082 - accuracy: 0.2513\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.6682 - accuracy: 0.2588\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 3.6275 - accuracy: 0.2656\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.6026 - accuracy: 0.2738\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.5632 - accuracy: 0.2807\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.5292 - accuracy: 0.2839\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.5295 - accuracy: 0.2887\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.5158 - accuracy: 0.2839\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.4698 - accuracy: 0.2992\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.4261 - accuracy: 0.3073\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 3.3859 - accuracy: 0.3173\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 3.3365 - accuracy: 0.3212\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 3.3094 - accuracy: 0.3339\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 3.2840 - accuracy: 0.3429\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 3.2399 - accuracy: 0.3487\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.2107 - accuracy: 0.3559\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.1799 - accuracy: 0.3640\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.1605 - accuracy: 0.3686\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.1350 - accuracy: 0.3733\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.1019 - accuracy: 0.3815\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.0814 - accuracy: 0.3873\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.0776 - accuracy: 0.3932\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.0490 - accuracy: 0.3958\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 3.0332 - accuracy: 0.4018\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 3.0009 - accuracy: 0.4000\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.9796 - accuracy: 0.4116\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.9781 - accuracy: 0.4107\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.9711 - accuracy: 0.4144\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.9283 - accuracy: 0.4206\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.9159 - accuracy: 0.4246\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.9083 - accuracy: 0.4315\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.8595 - accuracy: 0.4375\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.8396 - accuracy: 0.4468\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.8090 - accuracy: 0.4591\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.7907 - accuracy: 0.4647\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.7678 - accuracy: 0.4622\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.7419 - accuracy: 0.4699\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.7109 - accuracy: 0.4763\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.6743 - accuracy: 0.4907\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.6637 - accuracy: 0.4885\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.6435 - accuracy: 0.4886\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.6188 - accuracy: 0.4973\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.5951 - accuracy: 0.5069\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.5788 - accuracy: 0.5072\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.5746 - accuracy: 0.5127\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.5509 - accuracy: 0.5173\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 2.5263 - accuracy: 0.5224\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.5033 - accuracy: 0.5293\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.4918 - accuracy: 0.5308\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.4707 - accuracy: 0.5342\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.4431 - accuracy: 0.5432\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.4402 - accuracy: 0.5428\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.4256 - accuracy: 0.5436\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.4087 - accuracy: 0.5527\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.3844 - accuracy: 0.5535\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.3550 - accuracy: 0.5668\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.3441 - accuracy: 0.5652\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.3312 - accuracy: 0.5739\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.3050 - accuracy: 0.5747\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.3107 - accuracy: 0.5804\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.2878 - accuracy: 0.5838\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.2440 - accuracy: 0.5945\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.2334 - accuracy: 0.5959\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.2260 - accuracy: 0.5997\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.2137 - accuracy: 0.5974\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.1963 - accuracy: 0.6053\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.1892 - accuracy: 0.6109\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.1698 - accuracy: 0.6083\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.1603 - accuracy: 0.6077\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.1267 - accuracy: 0.6192\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.1156 - accuracy: 0.6270\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.0983 - accuracy: 0.6242\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.0747 - accuracy: 0.6323\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.0634 - accuracy: 0.6365\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.0500 - accuracy: 0.6393\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.0258 - accuracy: 0.6456\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.0440 - accuracy: 0.6420\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.0067 - accuracy: 0.6491\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 1.9947 - accuracy: 0.6542\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 1.9852 - accuracy: 0.6546\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 1.9679 - accuracy: 0.6585\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 1.9428 - accuracy: 0.6595\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 1.9575 - accuracy: 0.6604\n",
      "CPU times: user 3min 5s, sys: 21.4 s, total: 3min 26s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    " history = model.fit(dataset, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "1fXTEO3GJ282",
    "outputId": "c422869e-efbc-45e9-f367-b88db935e842"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "6Vc6PHgxa6Hm",
    "outputId": "e26bc59e-024a-4957-afa9-d4f6b72e102b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-921bbde7b99a>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "그래서 나는 어른들이 알아볼 수 있도록 보아 구렁이의 속을 그렸다 눈에 보이지 않는데 놀랐다 태어난 것이었다 그가 다시 물었다 되물었다 일이었다 요구해야 하는 법이니라 권위는 무엇보다도 사리에 두드렸다 내리뜨려 생각을하고 있었다 아름다와 주 주요한 것이다 바오밥나무를 잊으면 옷을 떨어진 않 아 분해를 차지하고 있다고 않기 때문이다 잘된것이 뭐야 이 산 그림 중의 이상 적은딱 그려 줘 라고 말하는 것이었다 그가 물었다 되물었다 것이었다 그는 다시 웃었다 이었다 집인지 2천 변하도록 잠근단 어디 고장을 만들 밝혀져 수도 잠을 하나 쉬운 않았다 했다 것이었다 어린 왕자가 물었다 물었다 속으로 중얼거렸다 대해서어른들과 아무것도 바라보며 그 꽃은 언제나 먼저 집인지 상상하지 못한다 명령했 방울을 마시며장사꾼에 몰라 바 본 적이 있었다 여행을 사람이 없는 알게\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"그래서 나는 어른들이 알아볼 수 있도록 보아 구렁이의 속을 그렸다\"\n",
    "next_words = 100\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = tokenizer.index_word[predicted[0]]\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX_yyEP95aKZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "195_Generating_LSTM_Sentences_YoungPrince_Korean_next_word.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
